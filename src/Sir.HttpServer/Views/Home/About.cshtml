@{
    Layout = "~/Views/_Layout.cshtml";
    ViewBag.Title = "About Crawl Crawler";
}
    <form action="/crawl/" method="post">
        <div class="blog-wrapper">
            <h1>About</h1>
            <p>
                Crawl Crawler is as much a JSON data HTTP API for private and corporate data hungry text projects as it is plain ol' non-tracking, keyword-based web search, results marked up with ad-free non-dynamic HTML, while serving no cookies.
            </p>
            <p>
                Crawl Crawler gives you the ability to search four grand sources of data, plus your own: the Common Crawl meta-data, text, and HTML repositories as well as WWW itself.
            </p>
            <a name="instructions"></a><h2>Instructions</h2>
            <p>
                There are three (types of) collections here that you may interact with.
            </p>
            <h3>First collection</h3>
            <p>
                The first collection is public read-only and is called <strong>"cc_wat"</strong>.
                It is maintained by Crawl Crawler and
                it is a product of analyzing Common Crawl's WAT meta data repository.
            </p>
            <p>
                Documents in this collection contain the queryable fields "title", "description",
                the "url" and these URL segment fields: "scheme", "host", "path" and "query".
            </p>
            <h3>Second collection</h3>
            <p>
                The second collection is also public read-only and is called <strong>"cc_wet"</strong>.
                Data fetched from Common Crawl or WWW will be added to it when you use your favorite browser to click on "Enrich"
                from a search result page and become refreshed, i.e. updated with more current data, when you click on "Refresh".
            </p>
            <p>
                Documents in the cc_wet collection contain the queryable field "description"
                that equals all text within the original document's body HTML element, and "url".
            </p>
            <h3>Third collection</h3>
            <p>
                The third collection type are slices. They are collections you create when you click
                <strong>"Save as"</strong> from a search result page.
                Anyone who knows the name of such a collection can both query it, append to it and refresh it.
            </p>
            <h3>Querying</h3>
            <h5>Hacking the URL</h5>
            <p>
                Specify one or more keywords in the "q" query string parameter.
            </p>
            <p>
                Use one or more "collection" query string parameters to direct your queries towards one or more collections.
            </p>
            <p>
                Use one or more "field" parameters to direct your queries towards one or more fields.
            </p>
            <p>
                Use one or more "select" parameters to define which document fields to include in your search result.
            </p>
            <p>
                Replace "OR=OR" query string entry with "AND=AND" for stricter interpretation of your query.
            </p>
            <p>
                Page by using "skip" and "take" parameters.
            </p>
            <h5>HTTP GET Accept:application/json</h5>
            <p>
                HTTPS GET /query/?field=title&field=description&q=embellished+sheath&OR=OR&skip=0&take=100&collection=cc_wat&select=title<br />
                Accept: application/json
            </p>
            <h5>JSON Query with HTTP POST</h5>
            <p>
                Define "skip", "take" and "select" parameters in the query string.
                Include your JSON query in the body of the request.
            </p>
            <p>
                HTTP POST /query/?skip=0&take=100&select=title<br />
                Content-Type:application/json <br />
                Accept: application/json
            </p>
            <pre>
    {
        "and":{
            "collection":"cc_wat",
            "host":"myfashion.com"
        },
        "or":{
            "collection":"cc_wet",
            "description":"prom dress wedding"
        },
        "not":{
            "collection":"cc_wat",
            "path":"kids teens"
        },
    }
            </pre>
            <p>
                There can be no more than one "and", "or" and "not" top-level field per JSON object.
            </p>
            <p>
                If child terms target the same collection as their parent, then you need to specify collection only once.
                There is no limit to the nesting depth other than one you set for yourself:
            </p>
            <pre>
    {
        "or":{
            "collection":"cc_wet",
            "description":"prom",
            "or":{
                "description":"dress",
                "or":{
                    "description":"wedding"
                }
            }
        }
    }
            </pre>
            <h2>Insert, append, update</h2>
            <p>
                You may create new collections and query, append to and update any public read-write enabled collection you know by name.
            </p>
            <h5>HTTP POST Content-Type:application/json</h5>
            <p>
                The insert, append and update HTTP APIs are unstable at this time.
                As soon as they become reliable they will be documented here.
            </p>
            <h2>User privacy</h2>
            <p>
                Crawl Crawler will not show you ads nor place cookies on your device.
                Crawl Crawler will not track you by any means.
                For security purposes and <a href="/toc">for a limited time</a> Crawl Crawler will keep a record of your IP address.
            </p>
            <h2>No data privacy</h2>
            <p>No document collection hosted by Crawl Crawler is private and all document collections are public.</p>
            <h2>Free as in freedom</h2>
            <p>
                Crawl Crawler is free of any affiliation with any dominant, or submissive (for that matter),
                search player.
                Not that there would be anything wrong with being so. We're just not.
            </p>
            <p>
                Crawl Crawler is built exclusively on OSS that you are free to run on your premises.
            </p>
            <p>
                You are free to use the Crawl Crawler GUI to query for data.
                You are equally free to use the Crawl Crawler HTTP API to query for data.
            </p>
            <h2>Not free as in beer</h2>
            <p>
                This service is mostly free as in beer but after the BETA period and for certain tasks,
                such as recurringly refreshing a document collection,
                or a slice of it, with textual content from WWW,
                there will be a small, quite reasonable fee involved.
            </p>
            <h2>Technology</h2>
            <p>
                We build <a href="https://github.com/didyougogo/commoncrawlcrawler/">Resin <sup>BETA</sup></a>,
                an open-source and extensible search engine.
            </p>
            <h2>Created by</h2>
            <p>
                This web based service was created by e-commerce solutions architect
                and search handy-man, Marcus Lager from Helsingborg, Sweden.
            </p>
        </div>
    </form>