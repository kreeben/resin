@{
    Layout = "~/Views/_Layout.cshtml";
    ViewBag.Title = "About Crawl Crawler";
}
    <form action="/crawl/" method="post">
        <div class="blog-wrapper">
            <h3>About</h3>
            <h2>What is Crawl Crawler?</h2>
            <p>
                Crawl Crawler is as much a data collector for private and corporate data hungry text expeditions as it is plain ol' non-tracking, keyword-based WWW search.
            </p>
            <p>
                Crawl Crawler gives you the ability to reach into five grand sources of data: the Common Crawl meta-data, text, and HTML repositories, WWW, and the data that you provide. 
            </p>
            <p>
                Crawl Crawler will barely index anything until you ask it to, so in the beginning the coverage will be weak. In the greatest of haste, though, full-text indices are wipped up for most which is important because the more you use Crawl Crawler the wider, deeper and more current its indices become, in real time.
            </p>
            <p>
                You interact with Crawl Crawler through a responsive web GUI as well as through a HTTP API.
            </p>
            <p>
                <a name="usage"></a>Use Crawl Crawler to:
                <ul>
                    <li><strong>execute queries</strong> that target all of its indices, some of them or one of them</li>
                    <li><strong>enrich</strong> your search results in a guided process where you connect meta-data with full text extracts and raw HTML from Common Crawl or WWW to give you a better search experience next time you search for the same topic</li>
                    <li><strong>build</strong> web site features and apps. For example, instead of implementing a search engine for your ecommerce site you use Crawl Crawler's Always Free HTTP Query API. If your site is not already indexed you simply ask Crawl Crawler to do it periodically and, bada-bing bada-bang, you have site-wide search.</li>
                </ul>
            </p>
            <p>
                Crawl Crawler is not free as in free beer. Some operations, such as periodically refreshing a slice of one of its search indices, are accompanied by a small, almost tiny fee.
            </p>
            <p>
                You're the captain of Crawl Crawler. There may be many captains but you are the captain as well. Where you steer, it will go.
            </p>
            <a name="instructions"></a><h2>Instructions</h2>
            <p>
                There are three (types of) collections here that you may interact with.
            </p>
            <h3>First collection</h3>
            <p>
                The first collection is public read-only and is called <strong>"cc_wat"</strong>.
                It is maintained by Crawl Crawler and
                it is a product of analyzing Common Crawl's WAT meta data repository.
            </p>
            <p>
                Documents in this collection contain the queryable fields "title", "description",
                the "url" and these URL segment fields: "scheme", "host", "path" and "query".
            </p>
            <h3>Second collection</h3>
            <p>
                The second collection is also public read-only and is called <strong>"cc_wet"</strong>.
                Data fetched from Common Crawl or WWW will be added to it when you use your favorite browser to click on "Enrich"
                from a search result page and become refreshed, i.e. updated with more current data, when you click on "Refresh".
            </p>
            <p>
                Documents in the cc_wet collection contain the queryable field "description"
                that equals all text within the original document's body HTML element, and "url".
            </p>
            <h3>Third collection</h3>
            <p>
                The third collection type are slices. They are collections you create when you click
                <strong>"Save as"</strong> from a search result page.
                Anyone who knows the name of such a collection can both query it, append to it and refresh it.
            </p>
            <h3>Querying</h3>
            <h5>Hacking the URL</h5>
            <p>
                Specify one or more keywords in the "q" query string parameter.
            </p>
            <p>
                Use one or more "collection" query string parameters to direct your queries towards one or more collections.
            </p>
            <p>
                Use one or more "field" parameters to direct your queries towards one or more fields.
            </p>
            <p>
                Use one or more "select" parameters to define which document fields to include in your search result.
            </p>
            <p>
                Replace "OR=OR" query string entry with "AND=AND" for stricter interpretation of your query.
            </p>
            <p>
                Page by using "skip" and "take" parameters.
            </p>
            <h5>HTTP GET Accept:application/json</h5>
            <p>
                HTTPS GET /query/?field=title&field=description&q=embellished+sheath&OR=OR&skip=0&take=100&collection=cc_wat&select=title<br />
                Accept: application/json
            </p>
            <h5>JSON Query with HTTP POST</h5>
            <p>
                Define "skip", "take" and "select" parameters in the query string.
                Include your JSON query in the body of the request.
            </p>
            <p>
                HTTP POST /query/?skip=0&take=100&select=title<br />
                Content-Type:application/json <br />
                Accept: application/json
            </p>
            <pre>
    {
        "and":{
            "collection":"cc_wat",
            "host":"myfashion.com"
        },
        "or":{
            "collection":"cc_wet",
            "description":"prom dress wedding"
        },
        "not":{
            "collection":"cc_wat",
            "path":"kids teens"
        },
    }
            </pre>
            <p>
                There can be no more than one "and", "or" and "not" top-level field per JSON object.
            </p>
            <p>
                If child terms target the same collection as their parent, then you need to specify collection only once. 
                There is no limit to the nesting depth other than one you set for yourself:
            </p>
            <pre>
    {
        "or":{
            "collection":"cc_wet",
            "description":"prom",
            "or":{
                "description":"dress",
                "or":{
                    "description":"wedding"
                }
            }
        }
    }
            </pre>
            <h2>Insert, append, update</h2>
            <p>
                You may create new collections and query, append to and update any public read-write enabled collection you know by name.
            </p>
            <h5>HTTP POST Content-Type:application/json</h5>
            <p>
                The insert, append and update HTTP APIs are unstable at this time.
                As soon as they become reliable they will be documented here.
            </p>
            <h2>User privacy</h2>
            <p>
                Crawl Crawler will not show you ads nor place cookies on your device.
                Crawl Crawler will not track you by any means.
                For security purposes and <a href="/toc">for a limited time</a> Crawl Crawler will keep a record of your IP address.
            </p>
            <h2>No data privacy</h2>
            <p>No document collection hosted by Crawl Crawler is private and all document collections are public.</p>
            <h2>Free as in freedom</h2>
            <p>
                Crawl Crawler is free of any affiliation with any dominant, or submissive (for that matter),
                search player.
                Not that there would be anything wrong with being so. We're just not.
            </p>
            <p>
                Crawl Crawler is built exclusively on OSS that you are free to run on your premises.
            </p>
            <p>
                You are free to use the Crawl Crawler GUI to query for data.
                You are equally free to use the Crawl Crawler HTTP API to query for data.
            </p>
            <h2>Not free as in beer</h2>
            <p>
                This service is mostly free as in beer but after the BETA period and for certain tasks,
                such as recurringly refreshing a document collection,
                or a slice of it, with textual content from WWW,
                there will be a small, quite reasonable fee involved.
            </p>
            <h2>Technology</h2>
            <p>
                We build <a href="https://github.com/didyougogo/commoncrawlcrawler/">Resin <sup>BETA</sup></a>,
                an open-source and extensible search engine.
            </p>
            <h2>Created by</h2>
            <p>
                This web based service was created by e-commerce solutions architect
                and search handy-man, Marcus Lager from Helsingborg, Sweden.
            </p>
        </div>
    </form>