@{
    Layout = "~/Views/_Layout.cshtml";
}
    <form action="/crawl/" method="post">
        <div class="blog-wrapper">
            <h2>About</h2>
            <p>
                At Crawl Crawler we've specialized in search.
                We crawl and index web pages, <a href="https://commoncrawl.org/the-data/get-started/#WAT-Format">WAT</a> and
                <a href="https://commoncrawl.org/the-data/get-started/#WET-Format">WET</a> files,
                and, from time to time, take on custom search solution projects.
            </p>
            <h3>We host multiple indices</h3>
            <p>
                We provide a search index (<a href="/?collection=cc_wat">cc_wat</a>) over the meta data from <a href="https://commoncrawl.org/">Common Crawl's</a> data set.
                You may use it to find and extract web page content from Common Crawl's wide web crawl sessions.
                We're doing our very best to try to automate that whole process, for your convenience.
            </p>
            <p>
                We also provide a partial search index (<a href="/?collection=cc_wet">cc_wet</a>) over the text content
                of web pages from the Common Crawl data set. Anytime anyone extracts content from a Common Crawl WET file
                via crawlcrawler.com, that data will end up in the public "cc_wet" search index, for everyone's convenience.
            </p>
            <p>
                You may search multiple indices in one query, like <a href="/?collection=cc_wat,cc_wet">this</a>.
            </p>
            <h3>We provide a public API</h3>
            <p>
                We provide a API for humans/browsers as well as a restful HTTP API that you may use to query any
                public index we host. These APIs also let you create your own data collections from slices of existing 
                collections or from data that you've provided via the write API. 
            </p>
            <h3>We'll crawl WWW for a small fee</h3>
            <p>
                We need a way to be able to pay for our servers so that we can provide Common Crawl crawling to the public,
                for free.
                That's why we offer to web crawl. Here's how to do that. 
            </p>
            <p>
                <strong>Step one:</strong> search the public "cc_wat" crawlcrawler index.
                <br /><strong>Step two:</strong> from the search result, click "crawl" then let crawlcrawler fetch a snapshot of the web content by making HTTP requests on your behalf to the original resources.
                Now you have a searchable web index of your favorite content.
            </p>
            <p>We'll also crawl WWW resources recurringly.</p>
            <h3>Technology stack</h3>
            <p>
                We build <a href="https://github.com/kreeben/resin">Resin</a>, an open-source and extensible search engine,
                on which we base most of our solutions.
            </p>
        </div>
    </form>