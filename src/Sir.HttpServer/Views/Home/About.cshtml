@{
    Layout = "~/Views/_Layout.cshtml";
    ViewBag.Title = "About Crawl Crawler";
}
    <form action="/crawl/" method="post">
        <div class="blog-wrapper">
            <h2>About</h2>
            <p>
                A crawl crawler is a search engine that utilizes indices that may be enriched with more data, in this case,
                textual web content, by fetching it from already crawled data or from WWW.
            </p>
            <p>
                Enrichment will create a better search experience when the next person visit
                Crawl Crawler to search the web using a query similar to yours.
                That's why it's such a great fit for crowd-sourcing.
            </p>
            <p>
                This service, <a href="/?collection=cc_wat">crawlcrawler.com</a>, is a <strong>free, open, non-tracking</strong> web based service
                created by search consultant Marcus Lager *.
                It's a lot like regular web search, only with a few more manual steps involved.
            </p>
            <p>Crawl Crawler is free of any dependance on or affiliation with any dominant market player. It is built using OSS. It will not track you.</p>
            <p>
                *) marcuslager (at gailm'n'such)
            </p>
            <h3>Three collections</h3>
            <p>
                There are three document collections that you may query.
            </p>
            <h4>First collection</h4>
            <p>
                The first collection is called <strong>"cc_wat"</strong>. It is maintained by Crawl Crawler and
                is a product of analyzing Common Crawl's
                <a href="https://commoncrawl.org/the-data/get-started/#WAT-Format">WAT meta data repository</a>.
            </p>
            <p>
                Documents in this collection contain the queryable fields "title", "description",
                the "url" and these URL segment fields: "scheme", "host", "path" and "query".
            </p>
            <h4>Second collection</h4>
            <p>
                The second collection is called <strong>"cc_wet"</strong>. It will be appended to when you
                use your favorite browser to click on <strong>"Enrich"</strong> from a search result page.
            </p>
            <p>
                Enrichment data can come from two sources. Crawl Crawler will fetch the complete text extraction
                of all pages in your search result
                from either (1) Common Crawl's <a href="https://commoncrawl.org/the-data/get-started/#WET-Format">WET textual data repository</a>,
                or from (2) the WWW, then analyze that text and append the indices to the secondary collection.
            </p>
            <p>
                Documents in the cc_wet collection contain the queryable fields "title" and "description".
            </p>
            <h4>Third collection</h4>
            <p>
                The third collection (type) are collections you create when you click
                "Save as" from a search result page or when you create and append to custom collections.
                Anyone who knows the name of a collection can both query and append to it.
            </p>
            <h3>Querying</h3>
            <i>
                The actual text content that lives inside of a HTML document's body tag will not always have been
                indexed by this search engine at the time of your query for all of the documents in your search result.
                We might have only had time to index the "title" and "description" meta data fields.
                When that's the case and you see an "Enrich" link on the search result page, go ahead and click it.
                Everybody will be better off from it.
            </i>
            <p>
                Use one or more "collection" query string parameters to direct your queries towards one or more collections.
            </p>
            <p>
                Use one or more "field" query string parameters to direct your queries towards one or more fields.
            </p>
            <p>
                Use one or more "select" query string parameters to define which document fields to include in your search result.
            </p>
            <p>
                Replace "OR=OR" query string entry with "AND=AND" for stricter interpretation of your query.
            </p>
            <p>
                Page by using "skip" and "take".
            </p>
            <h4>HTTP API</h4>
            <h5>Query with HTTP GET Accept:application/json</h5>
            <p>
                HTTPS GET /query/?field=title&field=description&q=embellished+sheath&OR=OR&skip=0&take=100&collection=cc_wat&select=title<br />
                Accept: application/json
            </p>
            <h5>JSON Query with HTTP POST Accept:application/json</h5>
            <p>
                HTTPS POST /query/?skip=0&take=100&select=title<br />
                Content-Type:application/json <br />
                Accept: application/json
            </p>
            <pre>
    {
        "and":{
            "collection":"cc_wat",
            "host":"myfashion.com"
        },
        "or":{
            "collection":"cc_wet",
            "title":"prom dress wedding",
            "description":"prom dress wedding"
        },
        "not":{
            "collection":"cc_wat",
            "path":"kids teens"
        },
    }
            </pre>
            <h4>Insert, append, update</h4>
            <p>
                You may create new collections that you may query and append to.
                In fact, you can query and append to any collection that you know by name.
            </p>
            <h5>HTTP POST Content-Type:application/json</h5>
            <p>
                The insert, append and update HTTP APIs are unstable at this time.
                As soon as they become reliable they will be documented here.
            </p>
            <h3>Technology</h3>
            <p>
                We build <a href="https://github.com/didyougogo/commoncrawlcrawler/">Resin <sup>BETA</sup></a>,
                an open-source and extensible search engine.
            </p>
        </div>
    </form>